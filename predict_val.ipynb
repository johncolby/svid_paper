{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict unknown validation or test set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext rpy2.ipython\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, ndarray as nd\n",
    "\n",
    "from unet import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Setup hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "\n",
    "args.data_dir = '../brats_2018_4D'\n",
    "args.weights_dir = '../params/baseline/bagged_ensemble/ensemble'\n",
    "args.output_dir = '../predictions/val__baseline__bagged_ensemble_soft_prediction_190101'\n",
    "\n",
    "# Training\n",
    "args.num_workers = 1\n",
    "GPU_COUNT = 1\n",
    "args.ctx = [mx.gpu(i) for i in range(GPU_COUNT)]\n",
    "# args.ctx = [mx.gpu(1)]\n",
    "\n",
    "# Unet\n",
    "args.num_downs = 4 # Number of encoding/downsampling layers\n",
    "args.classes = 4 # Number of classes for segmentation, including background\n",
    "args.ngf = 32 # Number of channels in base/outermost layer\n",
    "args.use_bias = True # For conv blocks\n",
    "args.use_global_stats = True # For BN blocks\n",
    "\n",
    "# Pre/post-processing\n",
    "args.pad_size_val = [240, 240, 160] # Should be input vol dims unless 'crop_size_val' is larger\n",
    "args.crop_size_val = [240, 240, 160] # Should be divisible by 2^num_downs\n",
    "args.overlap = 0 # Fractional overlap for val patch prediction, combined with voting\n",
    "args.output_dims = [240, 240, 155]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Setup data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('normalization_stats_test.npz')\n",
    "means_brain = nd.array(data['means_brain'])\n",
    "stds_brain  = nd.array(data['stds_brain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = MRISegDataset4D(root=args.data_dir, split='test', mode='val', crop_size=args.pad_size_val, transform=brats_transform, means=means_brain, stds=stds_brain)\n",
    "test_data = gluon.data.DataLoader(testset, batch_size=1, num_workers=args.num_workers, shuffle=False, last_batch='keep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Extract template NifTI header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = os.path.normpath(testset.paths()[0])\n",
    "img_path = os.path.join(subdir, os.listdir(subdir)[0])\n",
    "hdr = nib.load(img_path).header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Setup model and load ensemble weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnetGenerator(num_downs        = args.num_downs, \n",
    "                      classes          = args.classes, \n",
    "                      ngf              = args.ngf, \n",
    "                      use_bias         = args.use_bias, \n",
    "                      use_global_stats = args.use_global_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.collect_params().initialize(force_reinit=True, ctx=args.ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_paths = [os.path.join(args.weights_dir, X) for X in sorted(os.listdir(args.weights_dir))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Predict test data (for each set of model `weights` in ensemble)\n",
    "\n",
    "Save intermediate output maps with voxelwise softmax class probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brats_predict(model, data, crop_size, overlap, n_classes, ctx): \n",
    "    output = model(data.as_in_context(ctx)).squeeze().softmax(axis = 0).asnumpy()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_unpad(img, dims):\n",
    "    \"\"\"Unpad image vol back to original input dimensions\"\"\"\n",
    "    pad_dims = img.shape[1:]\n",
    "    xmin, ymin, zmin = 0, 0, 0\n",
    "    if pad_dims[0] > dims[0]:\n",
    "        xmin = (pad_dims[0] - dims[0]) // 2\n",
    "    if pad_dims[1] > dims[1]:\n",
    "        ymin = (pad_dims[1] - dims[1]) // 2\n",
    "    if pad_dims[2] > dims[2]:\n",
    "        zmin = (pad_dims[2] - dims[2]) // 2\n",
    "    return img[:, xmin : xmin + dims[0],\n",
    "                  ymin : ymin + dims[1],\n",
    "                  zmin : zmin + dims[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir)\n",
    "    \n",
    "for weights_path in tqdm(weights_paths):\n",
    "    model.load_parameters(weights_path, ctx=args.ctx[0])\n",
    "    output_dir = os.path.join(args.output_dir, 'runs', os.path.basename(weights_path).split('.params')[0])\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for isub, (data, _) in enumerate(tqdm(test_data)):\n",
    "        subID = os.path.basename(os.path.normpath(testset.paths()[isub]))\n",
    "        mask = brats_predict(model, data, args.crop_size_val, args.overlap, n_classes=args.classes, ctx=args.ctx[0])\n",
    "        mask = img_unpad(mask, args.output_dims) # Crop back to original BraTS dimensions\n",
    "        mask = np.flip(mask, 2) # Flip AP orientation back to original BraTS convention\n",
    "        mask = mask * 1000\n",
    "        mask = mask.transpose((1,2,3,0))\n",
    "        mask = mask.astype(np.int16)\n",
    "        mask_nii = nib.Nifti1Image(mask, None, header=hdr)\n",
    "        mask_nii.to_filename(os.path.join(output_dir, subID + '.nii.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Combine ensemble predictions\n",
    "\n",
    "* Assign output class to background `0` if predicted probability of background class is > 0.5.\n",
    "* Otherwise, assign output class to the maximum of the three foreground classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(args.output_dir, 'final')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "run_dirs_parent = os.path.join(args.output_dir, 'runs')\n",
    "run_dirs = [os.path.join(run_dirs_parent, X) for X in os.listdir(run_dirs_parent)]\n",
    "for isub in tqdm(range(len(testset))):\n",
    "    subID = os.path.basename(os.path.normpath(testset.paths()[isub]))\n",
    "    mask = np.empty(tuple(args.output_dims) + (args.classes,) + (len(run_dirs),))\n",
    "    for irun, run_dir in enumerate(run_dirs):\n",
    "        img_path = os.path.join(run_dir, subID + '.nii.gz')\n",
    "        mask[..., irun] = nib.load(img_path).get_fdata()\n",
    "    mask_sum = mask.sum(axis = -1)\n",
    "    mask_out = mask_sum[..., 1:].argmax(axis = -1) + 1\n",
    "    not_bg = mask_sum[..., 0] < (0.5 * len(run_dirs) * 1000)\n",
    "    mask_out = mask_out * not_bg\n",
    "    mask_out[mask_out == 3] = 4 # Convert tissue class labels back to original BraTS convention\n",
    "    mask_nii = nib.Nifti1Image(mask_out, None, header=hdr)\n",
    "    mask_nii.to_filename(os.path.join(output_dir, subID + '.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:unet]",
   "language": "python",
   "name": "conda-env-unet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
